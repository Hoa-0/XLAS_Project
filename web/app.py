import os
import sys
import cv2
import numpy as np
import streamlit as st

# ===============================
# FIX IMPORT src/*
# ===============================
ROOT_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
if ROOT_DIR not in sys.path:
    sys.path.append(ROOT_DIR)

from src.predict_model import predict_emotion_multi

# Webcam
from streamlit_webrtc import webrtc_streamer, VideoTransformerBase

# ===============================
# PAGE CONFIG
# ===============================
st.set_page_config(
    page_title="Facial Expression Recognition",
    page_icon="üòÉ",
    layout="centered"
)

st.title("üòÉ Facial Expression Recognition")
st.write("**M√¥n:** X·ª≠ l√Ω ·∫£nh s·ªë ‚Äì Nh·∫≠n d·∫°ng bi·ªÉu c·∫£m khu√¥n m·∫∑t (FER)")

# ===============================
# TAB UI
# ===============================
tab1, tab2 = st.tabs(["üì§ Upload ·∫£nh", "üì∑ Realtime Webcam"])

# ======================================================
# TAB 1: UPLOAD IMAGE (NHI·ªÄU KHU√îN M·∫∂T)
# ======================================================
with tab1:
    uploaded = st.file_uploader(
        "Upload ·∫£nh khu√¥n m·∫∑t (jpg / png)",
        type=["jpg", "png", "jpeg"]
    )

    if uploaded is not None:
        file_bytes = np.asarray(bytearray(uploaded.read()), dtype=np.uint8)
        img = cv2.imdecode(file_bytes, cv2.IMREAD_COLOR)

        results, img_draw = predict_emotion_multi(img)

        st.image(img_draw, channels="BGR", caption="K·∫øt qu·∫£ nh·∫≠n d·∫°ng")

        if len(results) == 0:
            st.warning("‚ö†Ô∏è Kh√¥ng ph√°t hi·ªán khu√¥n m·∫∑t n√†o")
        else:
            st.subheader("üìä K·∫øt qu·∫£:")
            for i, r in enumerate(results):
                st.write(
                    f"**Face {i+1}:** {r['label']} "
                    f"(confidence = {r['confidence']:.2f})"
                )

# ======================================================
# TAB 2: REALTIME WEBCAM
# ======================================================
class FERVideoProcessor(VideoTransformerBase):
    def transform(self, frame):
        img = frame.to_ndarray(format="bgr24")
        _, img_draw = predict_emotion_multi(img)
        return img_draw


with tab2:
    st.write("üé• Nh·∫≠n d·∫°ng bi·ªÉu c·∫£m khu√¥n m·∫∑t realtime")

    webrtc_streamer(
        key="fer-realtime",
        video_transformer_factory=FERVideoProcessor,
        media_stream_constraints={
            "video": True,
            "audio": False
        },
        async_transform=True
    )

# ===============================
# FOOTER
# ===============================
st.markdown("---")
st.caption("¬© 2025 ‚Äì FER Project | CNN ‚Äì LittleVGG | Streamlit")